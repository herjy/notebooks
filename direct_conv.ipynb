{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of using direct (real-space) convolutions in scarlet\n",
    "\n",
    "## Introduction\n",
    "The purpose of this notebook is to serve as a simple model to demonstrate how we can implement direct convolutions in scarlet in place of the current FFT convolutions. While designing this change I came across a few other changes that we can make to improve the speed of the code and potentially its memory footprint, while also lessening (or altogether eliminating) our dependence on autograd (or pytorch or jax). The other purpose is to remind my future self why I made some of the design choices that I made and give Peter and Remy the opportunity to correct and improve any elements of the design.\n",
    "\n",
    "### Gradients\n",
    "Let's start by thinking about why we switched to automatic gradients in the first place. We have a fairly simple model, where each extended source can be modeled as\n",
    "\n",
    "$M_k = A_k \\cdot S_k$\n",
    "\n",
    "where $M_k$ is the model for the $k^{th}$ component, $A_k$ is its amplitude and $S_k$ is its shape. So the model for the entire blend of $K$ components is\n",
    "\n",
    "$ M = \\sum_{k=1}^{K}{M_k}$.\n",
    "\n",
    "Given our data $D$ and weights $W$ our model without convolution is\n",
    "\n",
    "$ \\mathcal{L} = \\frac{1}{2}W\\cdot(D-M)^2$\n",
    "\n",
    "and with convolutions is\n",
    "\n",
    "$ \\mathcal{L_C} = \\frac{1}{2}W\\cdot(D-P(M))^2$\n",
    "\n",
    "where $P(M)$ is a function that performs a convolution on the entire model $M$. This function can be a direct analytic convolution like we first used in scarlet or a more complicated (to write) DFT.\n",
    "\n",
    "So initially we calculated the gradient of this model analytically by writing $\\mathcal{L}$ as \n",
    "\n",
    "$ \\mathcal{L} = \\frac{1}{2}W\\cdot(D-\\sum_{k=1}^{K}{A\\cdot S})^2$\n",
    "\n",
    "and calculating the entire derivative in one step. Even when we introduced a PSF we derived a rather pathalogical formula to apply the PSF that involved using a large tensor for $P$ that still allowed us to calculte the gradient in a single step. But once we switched to DFT convolutions on the entire image it became much more difficult to write an analytic gradient, especially knowing that our component models might get more complex, so we elected to use automatic gradients to speed up development. The other side benefit of using this method is that now our models could become more complex, as we didn't have to calcualte a complex derivative based on all of our parameters, for example our `PointSource` model became possible, as well as a future multiplicative models for dust.\n",
    "\n",
    "I think that this was the right thing to do and in general a good practice, as using autograd has certainly sped up development time, but using it comes with an overhead. This mostly involves the cpu time and memory necessary to generate the tree used by autograd to track each parameter so that it can properly be updated when the `grad` method is called. But looking back on what autograd actually does I think that it's time to implement a hybird approach to our gradients by thinking about what autograd does internally.\n",
    "\n",
    "Instead of attempting to calcualte the entire gradient in a single step, autograd would take our $\\mathcal{L_C}$ model above and use the chain rule. So to calculate the gradient of $A_i$ for model $i$ we would use\n",
    "\n",
    "$\\frac{\\partial\\mathcal{L_C}}{\\partial A_i} = \\frac{\\partial\\mathcal{L_C}}{\\partial P(M)} \\frac{\\partial P(M)}{\\partial M} \\frac{\\partial M}{\\partial M_i} \\frac{\\partial M_i}{\\partial A_i}$.\n",
    "\n",
    "So even when using DFTs for $P(M)$ we can analytically calculate all of the partial derivatives except for $\\frac{\\partial P(M)}{\\partial M}$, meaning we could significantly simplify the models we pass to autograd by calculating all of the known gradients and only using autograd to differntialte through the DFT.\n",
    "\n",
    "By switching to direct convolutions we can even calculate this term, so it is possible to build our gradient entirely analytically in the case where $\\frac{\\partial M_k}{\\partial x_k}$ is simple for some parameter $x_k$. In many cases we can still calculate $\\frac{\\partial M_k}{\\partial x_k}$ analytically, it will just be different than the usual $A_k$ and $S_k$ gradients. However, in cases where our initial model is complex and calculating the analytic gradient is either impossible or cumbersome (for example our `PointSource` model), we can implement whatever automatic gradient code the user chooses to calculate the gradients of only the $\\frac{\\partial M_k}{\\partial x_k}$ term. This gives us the benefit of speeding up runtime by giving autograd easier tasks but allowing us the flexibility to use autograd to quicky test a new model without too much analytic work to slow us down.\n",
    "\n",
    "### Direct convolutions in boxes\n",
    "\n",
    "This notebook also shows three different methods to calculate direct convolutions. All three methods are equally simple to implement and will be discussed in the next section, this section just holds the justification for using method 3 (hereafter refered to as the box method). This is similar to the calculation posted in slack (so feel free to skip to [Design](#Design)) only now I compare the following models:\n",
    "\n",
    "1. direct convolutions using autograd\n",
    "1. direct convolutions without autograd\n",
    "1. direct convolutions without autograd using the box method\n",
    "\n",
    "We first define the following:\n",
    "* $S$ = average area of a stamp\n",
    "* $I$ = Area of the entire image\n",
    "* $P$ = Area of the PSF\n",
    "* $k$ = number of sources in the image\n",
    "\n",
    "#### Method 1 (autograd)\n",
    "\n",
    "First we’ll look at using the current method but replacing the FFTs with convolutions in real space and the cost of each computation:\n",
    "Forward path:\n",
    "* First we have to pad each model from $S\\rightarrow I$: ~$kS$ operations\n",
    "* Sum all of the models together: $kI$ operations\n",
    "* Convolve the entire image with the PSF: $PI$ operations\n",
    "\n",
    "Backward path:\n",
    "* Derivative of the convolution operation for all pixels in the image: $PI$ operations\n",
    "* Derivative of the sum: $kI$ operations\n",
    "* Extract the box for each model: $kS$ operations\n",
    "\n",
    "**Total number of operations: $2(PI+kI+kS)$**\n",
    "\n",
    "#### Method 2 (without autograd)\n",
    "\n",
    "The backward path is the same as method 1, but now that we eliminate autograd we no longer have to pad our models and sum them in the image frame:\n",
    "\n",
    "Forward Path:\n",
    "* Insert each model into the larger model (we don’t have to pad now since we don’t need autograd to do the derivative, we can just update a slice): kS operations\n",
    "* Convolve the entire image with the PSF (same as before): PI operations\n",
    "\n",
    "Backward Path: same as method 1\n",
    "\n",
    "**Total number of operations: $2PI+kI+2kS$**\n",
    "\n",
    "#### Method 3 (box method)\n",
    "\n",
    "Now lets look at the box method, where we can update each box individually.\n",
    "\n",
    "Forward path: same as method 2\n",
    "\n",
    "Backward path:\n",
    "* Extract the region from the derivative for each source: kSP operations\n",
    "\n",
    "**Total number of operations: $PI + kS + kSP$**\n",
    "\n",
    "#### Comparison\n",
    "\n",
    "The difference between method 1 and method 2 is $kI$, which is substantial for large images with a large number of sources while the improvement from method 2 to method 3 is $P(I-kS) + k(I+S)$. The dominant term is the difference between the image area $I$ and the area of all the sources in the _model frame_, which should nearly always be smaller since most sources don't overlap in the model frame. Even in instances where they are nearly the same $k(I+S)$ will still offer a significant savings for large images (imagine a 1k X 1k blend with 100's of sources, which we do see in some of the HSC deep fields).\n",
    "\n",
    "## Design\n",
    "\n",
    "As stated in [Gradients](#Gradients) the main design change I am suggesting is to analytically calculate the first two partial derivatives in\n",
    "\n",
    "$\\frac{\\partial\\mathcal{L_C}}{\\partial x_i} = \\frac{\\partial\\mathcal{L_C}}{\\partial P(M)} \\frac{\\partial P(M)}{\\partial M} \\frac{\\partial M}{\\partial M_i} \\frac{\\partial M_i}{\\partial x_i}$\n",
    "\n",
    "ouselves, and leave it up to the model (and individual components) to calculate $\\frac{\\partial M}{\\partial M_i} \\frac{\\partial M_i}{\\partial x_i}$ for each model parameter $x_i$.\n",
    "\n",
    "I've identified the following changes to the code, which should be sufficient to implement this design:\n",
    "\n",
    "### General changes\n",
    "\n",
    "* `autograd` will be removed as a required dependency and all modules will `import numpy as np` except `fft.py`, which will still use autograd array boxes to allow us to backpropagate through FFTs if necessary (for example with shifting). However, if fft and ifft are the only methods that we use autograd for it might be useful to just implement those gradients ourselves too, although I can't say for sure how difficult that would be.\n",
    "\n",
    "### parameter.py\n",
    "\n",
    "I start with this module because it is the most confusing, mainly because I don't fully understand how `ArrayBox.register` works. Ideally we'd like to have a `Parameter` that is just a `numpy.array` with the added methods required by `AdaProx` to calculate gradients, since in the canonical case I don't think that we'll need autograd anymore. So I *think* that the following changes will be sufficient to make it possible to have autograd compatible parameters and autograd incompatible parameters (normal arrays) but I'd like Peter to confirm:\n",
    "* Keep `Parameter` as is\n",
    "* Create a new `AutogradParameter` that inherits from `Parameter`. Then in `parameter.py` we will use `ArrayBox.register(AutogradParameter)` and `VSpace.register(AutogradParameter, vspace_maker=Vspace.mappings[np.ndarray])`. This way ordinary models will have `Parameters` whose gradients will be updated by `AdaProx` while only the parameters that require autograd will use `AutogradParameter` (which I don't see being used much anymore except when testing out new models).\n",
    "\n",
    "Side note: shoud `parameter.py` be moved to `proxmin`? There isn't anything scarlet specific in here and this might prove useful to people using `proxmin` for optimization. This would also require a check as to whether or not autograd (or jax?) is installed to register the array box, and likely a setup option to decide which to use if they are both installed.\n",
    "\n",
    "### blend.py\n",
    "\n",
    "* `Blend.fit` will need to send a different `grad` function:\n",
    "    * Each observation will return either $\\frac{\\partial\\mathcal{L_C}}{\\partial M}$ or $\\frac{\\partial\\mathcal{L_C}}{\\partial P(M)}$ (see [observation.py](#observation.py)) that is the shape of the model frame.\n",
    "    * Methods 1 and 2\n",
    "        * The slice of $\\frac{\\partial\\mathcal{L_C}}{\\partial M}$ contained in each `Component.frame` is passed to\n",
    "          `Component.grad`.\n",
    "    * Box Method\n",
    "        * Each `Component` has only the pixels in its frame convolved  to calculate\n",
    "          $\\frac{\\partial P(M)}{\\partial M}$ and the result of $\\frac{\\partial\\mathcal{L_C}}{\\partial P(M)} \\frac{\\partial P(M)}{\\partial M}$ is passed to `Component.grad`.\n",
    "    * The result of `Component.grad` for all components is returned as a tuple (the same as the current implementation)\n",
    "\n",
    "### observation.py\n",
    "\n",
    "* We first calculate $\\frac{\\partial\\mathcal{L_C}}{\\partial P(M)} = -W\\cdot(D-P(M))$\n",
    "* Method 1 (with autograd)\n",
    "    * We create an `ArrayBox` for the model during `render` that is stored in the observation.\n",
    "      When `Observation.grad` is called we use autograd to calculate $\\frac{\\partial P(M)}{\\partial M}$ and multiply\n",
    "      that with $\\frac{\\partial\\mathcal{L_C}}{\\partial P(M)}$ and return $\\frac{\\partial\\mathcal{L_C}}{\\partial M}$.\n",
    "    * This will also allow us to use autograd for the multi-resolution observations\n",
    "* Method 2\n",
    "    * Both $\\frac{\\partial\\mathcal{L_C}}{\\partial P(M)}$ and $\\frac{\\partial P(M)}{\\partial M}$ are calculated\n",
    "      analytically in `Observation.grad` and returned, as in method 1.\n",
    "* Box method\n",
    "    * Only $\\frac{\\partial\\mathcal{L_C}}{\\partial P(M)}$ is calculated and returned from `Observation.grad`,\n",
    "      where `Blend.grad` will calculate $\\frac{\\partial P(M)}{\\partial M_i}$ for each component model $M_i$.\n",
    "\n",
    "### component.py\n",
    "\n",
    "* `Component`\n",
    "    * Will now contain a `grad` method that must be overridden in inherited classes.\n",
    "      `grad` takes the upstream gradients as an argument, the same as autograd,\n",
    "      and calculates $\\frac{\\partial M_i}{\\partial x_i}$ for each parameter $x_i$,\n",
    "      returning the result as a tuple.\n",
    "    * `get_model` will no longer pad, as `blend.get_model` will insert the model for each component into\n",
    "      an image the size of `blend.frame`.\n",
    "* `FactorizedComponent`\n",
    "    * All of the `_pad_...` methods will be removed\n",
    "    * `grad` will analytically calculate $\\frac{\\partial M_i}{\\partial A_i}$ and $\\frac{\\partial M_i}{\\partial S_i}$\n",
    "      and return a tuple with the total gradient updates for $A_i$ and $S_i$ (and the shift parameters if necessary)\n",
    "    * With `shift=True`\n",
    "        * `get_model` will build the model and store that in an `ArrayBox`, which is then shifted in k-space\n",
    "          and returned\n",
    "        * `grad` will use autograd to calculate $\\frac{\\partial M_i}{\\partial shift_y}$\n",
    "          and $\\frac{\\partial M_i}{\\partial shift_x}$\n",
    "* `FunctionComponent`\n",
    "    * `get_model` will build the model from the parameters exactly as before\n",
    "    * By default `grad` will assume that the parameters are `AutogradParameter`s and\n",
    "      calcualate $\\frac{\\partial M_i}{\\partial x_i}$ for each parameter.\n",
    "      This can be overridden by inherited classes with a known gradient.\n",
    "\n",
    "* `ComponentTree`\n",
    "    * For now all of our models are additive and have equal weight, so $\\frac{\\partial M}{\\partial M_i} = 1$.\n",
    "    * This makes `grad` easy, since it will just pass the result of $\\frac{\\partial\\mathcal{L_C}}{\\partial M}$\n",
    "      through to `Component.grad` for each component\n",
    "    * `get_model` is similar, except that now have two different case:\n",
    "        1. All of the components have the same frame\n",
    "            * In this case `get_model` can easily add all of the models together and return the result\n",
    "        1. Some components have different frames\n",
    "            * In this case we need to create a new frame for the `ComponentTree` that is the minimum size needed\n",
    "              to contain all of its components and return that in `get_model`.\n",
    "            * `grad` will now need to pass only the correct slice of each gradient through to its components\n",
    "            * `set_frame` will not pass the frame to its children, since they are already different sizes.\n",
    "\n",
    "### source.py\n",
    "\n",
    "* The only changes to `ExtendedSource` and `MultiComponentSource` is that if `shifting=True` then the shift will be a `AutogradParameter`, since `FactorizedComponent` and `ComponentTree` will implement all of the necessary upgrades to calcualte $\\frac{\\partial M_i}{\\partial A_i}$ and $\\frac{\\partial M_i}{\\partial S_i}$\n",
    "* `PointSource` will also remain unchanged for now, since implementing an analytic derivative to shift the PSF requires knowlege of the PSF function. Since we are likely to continue using gaussian PSFs in the future it may be worth our while to inherit from `PointSource` with a class that implements a gaussian PSF and an analytic gradient.\n",
    "\n",
    "### psf.py\n",
    "\n",
    "* `autograd.numpy` and `autograd.scipy` will be moved into the `gaussian` and `moffat` functions, since those are the only ones required to be compatible with autograd (because of `PointSource`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import autograd.numpy as anp\n",
    "from autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scarlet.operators_pybind11 import apply_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFoAAABZCAYAAAC+PDOsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABB5JREFUeJztnE+IVVUcxz/fxvlD0yTWCEVJZQ3BuKkYDKuF5KaGyEUtbBHtZAihoI0guGhfQRCFkOAiUPpDiEyEaJsWTumgwTRUYxBJLTJlRoNGRn4u7k0Gfbx73p/ze3H9feDCee+d+7s/PhzOveeed47MjCA/t/U6gVuFEO1EiHYiRDsRop0I0U6EaCdCtBMh2ok1OYIOaNCGGO44ztWxwS5kU9D3y3LHMf7lH67Ysto5N4voIYZ5Uts6jrP4/iNdyKZg7eRCxzFm7Fjb50bX4USIdiJEOxGinUgSLek5ST9JWpC0O3dSdaRStKQ+4APgeWAceEXSeO7E6kZKi94MLJjZr2Z2BTgIbM+bVv1IEX0f8Puqz+fK74IWSBmwNBoJ3TTRKGknsBNgiNs7TKt+pLToc8CGVZ/vB/64sZKZ7TOzCTOb6Kd7Q+e6kCL6e2BM0kOSBoAdwOG8adWPyq7DzFYk7QK+BvqA/WY2lz2zmpH0UsnMpoHpzLnUmhgZOhGinQjRTmR58b8yOsz5l7Z0HOfUYx92IZuCh9+b6jjG8jsn2j43WrQTIdqJEO1EiHYiRDsRop0I0U6EaCdCtBMh2okQ7USIdiJEOxGinQjRToRoJ0K0EyHaCeXYRuJO3WXdWMPywtzFLmRTcGTTuo5jzNgxluxCW4uFokU7EaKdCNFOhGgnUpZWbJD0jaR5SXOS3vBIrG6k/IFmBXjLzGYljQCnJB01sx8z51YrKlu0mf1pZrNl+RIwTyytaJmW+mhJDwKPAzM5kqkzyf+9k3QH8DnwppktNfg91rA0IXVBZz+F5E/M7ItGdWINS3NSnjoEfAzMm9m7+VOqJykt+mngVeBZSafLYzJzXrUjZbHQtzReaxi0QIwMnQjRToRoJ0K0E1lmWCT9BfxWUW0UON/1i+flUTMbaefELKuyzGx9VR1JJ81sIsf1cyHpZLvnRtfhRIh2opei9/Xw2u3Sds5ZbobBzUTX4URW0VX75UkalHSo/H2mnFjoKSlzpJK2Slpc9ZJtb2VgM8tyUOxWcxbYCAwAZ4DxG+q8DnxUlncAh3Ll00Le9wJPlOUR4OcGeW8FjrQSN2eLTtkvbztwoCx/Bmwr33/3jFxzpDlFp+yXd72Oma0Ai8DdGXNqiYo50i2Szkj6StKmqlhZRoYlKfvlJe2p1wsq5khngQfM7HI5CfIlMNYsXs4WnbJf3vU6ktYAa4ELGXNKomqO1MyWzOxyWZ4G+iWNNouZU3TKfnmHgdfK8svAcevxg33KHKmke/67l0jaTOHx76aBM9/BJynu2meBPeV3bwMvluUh4FNgAfgO2Pg/eOp4hqL7+gE4XR6TwBQwVdbZBcxRPEmdAJ6qihsjQydiZOhEiHYiRDsRop0I0U6EaCdCtBMh2olrj/670Jk0PD0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "units = 0.05\n",
    "psf = np.array([[0,4,0],[2,6,3],[0,5,0]]) * units\n",
    "_psf = psf[::-1, ::-1]\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(psf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter_coords(filter_values, center=None):\n",
    "    # Attempt to automatically create coordinate grid\n",
    "    if len(filter_values.shape)!=2:\n",
    "        raise ValueError(\"`filter_values` must be 2D\")\n",
    "    if center is None:\n",
    "        if filter_values.shape[0] % 2 == 0 or filter_values.shape[1] % 2 == 0:\n",
    "            msg = \"\"\"Ambiguous center of the `filter_values` array,\n",
    "                     you must use a `filter_values` array\n",
    "                     with an odd number of rows and columns or\n",
    "                     calculate `coords` on your own.\"\"\"\n",
    "            raise ValueError(msg)\n",
    "        center = [filter_values.shape[0]//2, filter_values.shape[1]//2]\n",
    "    x = np.arange(filter_values.shape[1])\n",
    "    y = np.arange(filter_values.shape[0])\n",
    "    x,y = np.meshgrid(x,y)\n",
    "    x -= center[1]\n",
    "    y -= center[0]\n",
    "    coords = np.dstack([y,x])\n",
    "    return coords\n",
    "\n",
    "\n",
    "def get_filter_slices(coords):\n",
    "    \"\"\"Get the slices in x and y to apply a filter\n",
    "    \"\"\"\n",
    "    z = np.zeros((len(coords),), dtype=int)\n",
    "    # Set the y slices\n",
    "    y_start = np.max([z, coords[:,0]], axis=0)\n",
    "    y_end = -np.min([z, coords[:,0]], axis=0)\n",
    "    # Set the x slices\n",
    "    x_start = np.max([z, coords[:,1]], axis=0)\n",
    "    x_end = -np.min([z, coords[:,1]], axis=0)\n",
    "    return y_start, y_end, x_start, x_end\n",
    "\n",
    "\n",
    "def get_component_model(sed, morph, center):\n",
    "    y,x = center\n",
    "    box = (slice(y-1, y+2), slice(x-1, x+2))\n",
    "    return sed[:, None, None]*morph[None, :, :], box\n",
    "\n",
    "\n",
    "def get_full_model(seds, morphs, centers):\n",
    "    model = np.zeros((3, 12, 12))\n",
    "    boxes = []\n",
    "    for k in range(len(seds)):\n",
    "        _model, box = get_component_model(seds[k], morphs[k], centers[k])\n",
    "        model[:, box[0], box[1]] += _model\n",
    "        boxes.append(box)\n",
    "    return model, box\n",
    "\n",
    "\n",
    "def convolve(image, psf, slices):\n",
    "    result = np.empty(image.shape, dtype=image.dtype)\n",
    "    for band in range(len(image)):\n",
    "        apply_filter(image[band], psf.reshape(-1), slices[0], slices[1], slices[2], slices[3], result[band])\n",
    "    return result\n",
    "\n",
    "\n",
    "def logL(data, model, weights=1):\n",
    "    return 0.5*np.weights*(data-model)**2\n",
    "\n",
    "\n",
    "def grad_logL(data, model, weights=1):\n",
    "    return weights*(model-data)\n",
    "\n",
    "def grad_convolve_a(grad_logL, psf, slices):\n",
    "    return convolve(grad_logL, psf[::-1, ::-1], slices)\n",
    "\n",
    "def img2rgb(image):\n",
    "    rgb = image.copy()\n",
    "    rgb[rgb>255] = 255\n",
    "    rgb[rgb<0] = 0\n",
    "    rgb = rgb.astype(np.uint8)\n",
    "    rgb = np.transpose(rgb, axes=(1,2,0))\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = np.zeros((3, 12, 12))\n",
    "centers = [(5,4), (4,7), (6, 7), (7,6)]\n",
    "seds = np.array([[500,0,0], [0,0,500], [0,500,0], [200,400,400]])\n",
    "for k, (y,x) in enumerate(centers):\n",
    "    images[:, y-1:y+2, x-1:x+2] += psf[None, :, :] * seds[k][:,None,None]\n",
    "rgb = img2rgb(images)\n",
    "plt.imshow(rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphs = []\n",
    "for k, (y,x) in enumerate(centers):\n",
    "    morph = np.zeros((3,3))\n",
    "    morph[1,1] = 1\n",
    "    morphs.append(morph)\n",
    "morphs = np.array(morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, boxes = get_full_model(seds, morphs, centers)\n",
    "plt.imshow(img2rgb(model))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = get_filter_coords(psf)\n",
    "slices = get_filter_slices(coords.reshape(-1, 2))\n",
    "result = convolve(model, psf, slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img2rgb(result))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(images-result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
